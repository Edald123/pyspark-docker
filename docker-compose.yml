services:
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080" # Spark Master Web UI
      - "7077:7077" # Spark Master RPC
    volumes:
      - ./app:/app # Mount application code
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf # Mount Spark configuration file
      - spark-logs:/opt/spark/logs # Mount for logs
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "512m"

  spark-worker-1:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8081:8081" # Spark Worker Web UI
    volumes:
      - ./app:/app # Mount application code
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf # Mount Spark configuration file
      - spark-logs:/opt/spark/logs # Mount for logs
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: "2g"

  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8082:8081" # Spark Worker Web UI
    volumes:
      - ./app:/app # Mount application code
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf # Mount Spark configuration file
      - spark-logs:/opt/spark/logs # Mount for logs
    deploy:
      resources:
        limits:
          cpus: "1.5"
          memory: "2g"

volumes:
  spark-logs:
    driver: local
